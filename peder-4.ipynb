{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install openpyxl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfrom statistics import *\nfrom statistics import stdev\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n#import openpyxl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''file = r'../input/public/Public_transportation_infrastructure.xlsx'\nxl = pd.ExcelFile(file)\nprint(xl.sheet_names)\ndf1 = xl.parse('Sheet6')'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''file = r'../input/bysykk/Bysykkeloversikt_2019.xlsx'\nxl = pd.ExcelFile(file)\nprint(xl.sheet_names)\ndf1 = xl.parse('Analyse')'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''df1 = xl.parse('juli_2019')\ndf1'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nfile = r'../input/public/Public_transportation_infrastructure.xlsx'\nxl2 = pd.ExcelFile(file)\nprint(xl2.sheet_names)\n#df1 = xl.parse('Analyse')\ndf10 = pd.read_excel(xl2, 'Sheet6')\ndf10.to_pickle('Sheet6.pkl')\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#['Analyse', 'april_2019', 'mai_2019', 'juni_2019', 'juli_2019', 'august_2019', 'september_2019', 'oktober_2019']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''df1 = pd.read_excel(xl, 'Analyse')\ndf1.to_pickle('Analyse.pkl')\n\ndf2 = pd.read_excel(xl, 'april_2019')\ndf2.to_pickle('april_2019.pkl')\n\ndf3 = pd.read_excel(xl, 'mai_2019')\ndf3.to_pickle('mai_2019.pkl')\n\ndf4 = pd.read_excel(xl, 'juni_2019')\ndf4.to_pickle('juni_2019.pkl')\n\ndf5 = pd.read_excel(xl, 'juli_2019')\ndf5.to_pickle('juli_2019.pkl')\n\ndf6 = pd.read_excel(xl, 'august_2019')\ndf6.to_pickle('august_2019.pkl')\n\ndf7 = pd.read_excel(xl, 'september_2019')\ndf7.to_pickle('september_2019.pkl')\n\ndf8 = pd.read_excel(xl, 'oktober_2019')\ndf8.to_pickle('oktober_2019.pkl')\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.read_pickle(r'../input/dataset-pkl/Analyse.pkl')\ndf3 = pd.read_pickle(r'../input/dataset-pkl/april_2019.pkl')\ndf4 = pd.read_pickle(r'../input/dataset-pkl/mai_2019.pkl')\ndf5 = pd.read_pickle(r'../input/dataset-pkl/juni_2019.pkl')\ndf6 = pd.read_pickle(r'../input/dataset-pkl/juli_2019.pkl')\ndf7 = pd.read_pickle(r'../input/dataset-pkl/august_2019.pkl')\ndf8 = pd.read_pickle(r'../input/dataset-pkl/september_2019.pkl')\ndf9 = pd.read_pickle(r'../input/dataset-pkl/oktober_2019.pkl')\ndf10 = pd.read_pickle(r'../input/sheet6/Sheet6.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=df1.dropna(axis=1,how='all')\ndf1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=df1.replace(np.nan,0)\ndf1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in df1.columns:\n    print(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=df1.rename(columns={'Unnamed: 1':'c_april'})\ndf1=df1.rename(columns={'Unnamed: 4':'c_may'})\ndf1=df1.rename(columns={'Unnamed: 7':'c_jun'})\ndf1=df1.rename(columns={'Unnamed: 10':'c_july'})\ndf1=df1.rename(columns={'Unnamed: 13':'c_aug'})\ndf1=df1.rename(columns={'Unnamed: 16':'c_sep'})\ndf1=df1.rename(columns={'Unnamed: 19':'c_oct'})\n\ndf1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\nimport os\nimport csv\nfrom datetime import datetime\ndf1 = df1.rename(columns={datetime.strptime('2019-04-01 00:00:00', '%Y-%m-%d %H:%M:%S'): '04'})\ndf1 = df1.rename(columns={datetime.strptime('2019-05-01 00:00:00', '%Y-%m-%d %H:%M:%S'): '05'})\ndf1 = df1.rename(columns={datetime.strptime('2019-06-01 00:00:00', '%Y-%m-%d %H:%M:%S'): '06'})\ndf1 = df1.rename(columns={datetime.strptime('2019-07-01 00:00:00', '%Y-%m-%d %H:%M:%S'): '07'})\ndf1 = df1.rename(columns={datetime.strptime('2019-08-01 00:00:00', '%Y-%m-%d %H:%M:%S'): '08'})\ndf1 = df1.rename(columns={datetime.strptime('2019-09-01 00:00:00', '%Y-%m-%d %H:%M:%S'): '09'})\ndf1 = df1.rename(columns={datetime.strptime('2019-10-01 00:00:00', '%Y-%m-%d %H:%M:%S'): '10'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=df1[1:]\ndf1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.to_dict()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one = df1[['04','05','06','07','08','09','10']].melt().rename({'variable':'','value':'COL1.'},axis=1)\none","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"two = df1[['c_april','c_may','c_jun','c_july','c_aug','c_sep','c_oct']].melt().drop('variable',axis=1).rename({'value':'count'},axis=1)\ntwo[1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out = pd.concat([one,two],axis=1).reindex(['COL1.','count',''], axis=1)\nout = out.replace(np.nan, '', regex=True)\n#out = out[1:]\nout = out.rename(columns={'': 'month'})\nout.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out['month'] = out['month'].astype('int64')\nout['count'] = out['count'].astype('int64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out = out.sort_values(['count'], ascending=[False])\n#out=out.drop(['level_0'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataTypeSeries = df3.dtypes\nprint('Data type of each column of Dataframe :')\nprint(dataTypeSeries)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The shape of data set.\nprint('The shape of our features is:', df3.shape)\ndf3=df3.replace(np.nan,0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3.isnull().sum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df5['start_station_id'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res1 = df3.append(df4).reset_index()\nres2 = res1.append(df5).reset_index()\nres2=res2.drop(['level_0','index','Unnamed: 0'], axis=1)\n\nres3 = res2.append(df6).reset_index()\n\nres4 = res3.append(df7).reset_index()\nres4=res4.drop(['level_0','index'], axis=1)\n\n\nres5 = res4.append(df8).reset_index()\n\nresult = res5.append(df9).reset_index()\nresult=result.drop(['index','Unnamed: 0'], axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result['month'] = pd.DatetimeIndex(result['started_at']).month\nresult[:3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(result['month'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result['start_station_name'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result['combined'] = result['start_station_id'].astype(str)+result['end_station_id'].astype(str)\nresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result['combined'].nunique()\n#we just have 54777 uniqe FROM to TO station . #lets sum the duration of each similar row.\n#and drop the duplicate row.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.describe().round(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"j = result.sort_values(['duration'], ascending=[False])\nj[50:100]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see shortest trips were 61 seconds (Citi Bike ignores trips that are 60 seconds or less). The longest was 1194151.00 seconds (or 902 hours) which sounds like someone didn’t dock their bike. Numbers that large will throw off the mean, so we’ll want to address that."},{"metadata":{"trusted":true},"cell_type":"code","source":"mean = result.loc[result['duration']<30000,'duration'].mean()\nmean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nresult[\"duration\"] = np.where(result[\"duration\"] >30000, mean,result['duration'])\nresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.describe().round(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Group by based on the combined id and we some the duration \nresult[\"sum\"] = result.groupby('combined')['duration'].transform('sum')\nresult = result.drop_duplicates('combined')\nresult.sort_values(['sum'], ascending=[False])[:10]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check[\"duration\"].sum(axis = 0, skipna = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncheck2 = out[out['start_station_name']=='Schous plass']\ncheck2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out= out.rename({'COL1.': 'start_station_name'}, axis=1)\nout[:3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result2=result.merge(out,right_on=['start_station_name','month'],left_on=['start_station_name','month'])\nresult2.sort_values(['sum'], ascending=[False])[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result2['tripminutes'] = result2['sum'] // 60\nresult2['triphour'] = result2['sum'] // 3600","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_sort = result2.sort_values(['sum'], ascending=[False])\nresult_sort = result_sort[:10]\nresult_sort","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(out.shape)\nprint(result.shape)\nprint(df1.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install folium\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n#installation\n# Create a world map to show distributions of users \nimport folium\nfrom folium.plugins import MarkerCluster\n#empty map\nworld_map= folium.Map(tiles=\"CartoDB dark_matter\")\nmarker_cluster = MarkerCluster().add_to(world_map)\n#for each coordinate, create circlemarker of user percent\nfor i in range(len(result_sort)):\n        lat = result_sort.iloc[i]['start_station_latitude']\n        long = result_sort.iloc[i]['start_station_longitude']\n           \n        \n        radius=5\n        popup_text = \"\"\"Users : {}<br>\"\"\"\n        popup_text = popup_text.format(result_sort.iloc[i]['start_station_name'])\n\n\n        folium.CircleMarker(location = [lat, long], radius=radius, popup= popup_text, fill =True).add_to(marker_cluster)\n\nplt.savefig('x', dpi=300)\n#show the map\nworld_map\n#tiles=\"CartoDB dark_matter\"\n#cartodbpositron","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# select the first occurrence of each station id\nlocations = result2.groupby(\"start_station_id\").first()\nlocations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# and select only the tree columns we are interested in\nlocations = locations.loc[:, [\"start_station_latitude\",\n                              \"start_station_longitude\",\n                              \"start_station_name\"]]\n\nlocations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"departure_counts =  result.groupby(\"start_station_id\").count()\ndeparture_counts\n# select one column\ndeparture_counts = departure_counts.iloc[:,[0]]\n# and rename that column\ndeparture_counts.columns= [\"Departure Count\"]\ndeparture_counts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arrival_counts =  result.groupby(\"end_station_id\").count()\narrival_counts\narrival_counts = arrival_counts.iloc[:,[0]]\narrival_counts.columns= [\"arrival_counts\"]\narrival_counts\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trip_counts = departure_counts.join(locations).join(arrival_counts)\ntrip_counts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x= result['start_station_name'].unique().tolist()\ny= result['end_station_name'].unique().tolist()\nset(x) == set(y)  #arrival and departure stations are the same. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trip_counts['sum_ar_dp'] = trip_counts['Departure Count'] + trip_counts['arrival_counts']\ntrip_counts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trip_counts = trip_counts.sort_values(['sum_ar_dp'], ascending=[False])\ntrip_counts_10 = trip_counts[:10]\ntrip_counts_10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import division\ng = [57308,72230,54765,53751,51334,49502,49484,46959,46909,42501]\ndevision=[]\nfor i in g:\n    a= i/8000\n    devision.append(a)\ndevision","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n#installation\n# Create a world map to show distributions of users \nimport folium\nfrom folium.plugins import MarkerCluster\n#empty map\nworld_map= folium.Map(tiles=\"cartodbpositron\")\nmarker_cluster = MarkerCluster().add_to(world_map)\n#for each coordinate, create circlemarker of user percent\nfor i in range(len(trip_counts_10)):\n        lat = trip_counts_10.iloc[i]['start_station_latitude']\n        long = trip_counts_10.iloc[i]['start_station_longitude']\n           \n        \n        radius=5\n        popup_text = \"\"\"Users : {}<br>\"\"\"\n        popup_text = popup_text.format(trip_counts_10.iloc[i]['start_station_name'])\n\n\n        folium.CircleMarker(location = [lat, long], radius=radius, popup= popup_text, fill =True).add_to(marker_cluster)\n\nplt.savefig('x', dpi=300)\n#show the map\nworld_map\n#tiles=\"CartoDB dark_matter\"\n#cartodbpositron","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import folium\nfrom folium.plugins import MarkerCluster\n#empty map\nfolium_map= folium.Map(tiles=\"cartodbpositron\")\nmarker_cluster = MarkerCluster().add_to(world_map)\n\nfor index, row in trip_counts.iterrows():\n    net_departures = (row[\"sum_ar_dp\"])\n    radius = net_departures/8000\n    if radius in devision:\n        color=\"#E37222\" # tangerine\n    else:\n        color=\"#0A8A9F\" # teal\n    #popup_text = \"\"\"Users : {}<br>\"\"\"\n    #popup_text = popup_text.format(hh.iloc[i]['start_station_name'])\n    \n    popup_text = \"\"\"{}<br>\n                total departures: {}<br> \n                total arrivals: {}<br>\n                net departures: {}\"\"\"\n    popup_text = popup_text.format(row[\"start_station_name\"],\n                               row[\"arrival_counts\"],\n                               row[\"Departure Count\"],\n                               net_departures)\n    folium.CircleMarker(location=(row[\"start_station_latitude\"],\n                                  row[\"start_station_longitude\"]),\n                        radius=radius,\n                        color=color,\n                        fill=True,popup= popup_text).add_to(folium_map)\n   \n\n\n\n\n    \nfolium_map\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that our data is ready, let’s add it to the map. We’ll iterate over all the rows in the DataFrame we just created and add a marker for each row. We assign a different color depending on the sign of the net departures. If there are more departures than arrivals, we draw a tangerine circle, other wise we use teal."},{"metadata":{"trusted":true},"cell_type":"code","source":"import folium\nfrom folium.plugins import MarkerCluster\n#empty map\nfolium_map= folium.Map(tiles=\"CartoDB dark_matter\")\nmarker_cluster = MarkerCluster().add_to(world_map)\n\nfor index, row in trip_counts.iterrows():\n    net_departures = (row[\"Departure Count\"]-row[\"arrival_counts\"])\n    radius = net_departures/800\n    if net_departures>0:\n        color=\"#E37222\" # tangerine\n    else:\n        color=\"#0A8A9F\" # teal\n    #popup_text = \"\"\"Users : {}<br>\"\"\"\n    #popup_text = popup_text.format(hh.iloc[i]['start_station_name'])\n    \n    popup_text = \"\"\"{}<br>\n                total departures: {}<br> \n                total arrivals: {}<br>\n                net departures: {}\"\"\"\n    popup_text = popup_text.format(row[\"start_station_name\"],\n                               row[\"arrival_counts\"],\n                               row[\"Departure Count\"],\n                               net_departures)\n    folium.CircleMarker(location=(row[\"start_station_latitude\"],\n                                  row[\"start_station_longitude\"]),\n                        radius=radius,\n                        color=color,\n                        fill=True,popup= popup_text).add_to(folium_map)\n   \n\n\n\n\n    \nfolium_map\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"customize the effect of overlapping paths to show traffic density, and\nwe will add a glow effect to draw attention to high density areas.\n"},{"metadata":{},"cell_type":"markdown","source":"Creating the intensity map\nAdding lines: We will start by creating a gray scale image where intensity in each pixel is proportional to the number of trips passing through that pixel. We’ll use a numpy array to store the pixel values."},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image, ImageDraw\nimport numpy as np\nimport pandas as pd\nimport folium\nimport matplotlib.pyplot as plt\nimport matplotlib.colors\nfrom matplotlib.colors import LinearSegmentedColormap, rgb_to_hsv, hsv_to_rgb\nimport scipy.ndimage.filters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_lines(image_array, xys, width=1, weights=None):\n    \"\"\"\n    Add a set of lines (xys) to an existing image_array\n    width: width of lines\n    weights: [], optional list of multipliers for lines. \n    \"\"\"\n    \n    for i, xy in enumerate(xys):  # loop over lines\n        # create a new gray scale image\n        image = Image.new(\"L\",(image_array.shape[1], image_array.shape[0]))\n        \n        # draw the line\n        ImageDraw.Draw(image).line(xy, 200, width=width)\n        \n        #convert to array\n        new_image_array = np.asarray(image, dtype=np.uint8).astype(float)\n        \n        # apply weights if provided\n        if weights is not None:\n            new_image_array *= weights[i]\n            \n        # add to existing array\n        image_array += new_image_array\n\n    # convolve image\n    new_image_array = scipy.ndimage.filters.convolve(image_array, get_kernel(width*4)) \n    return new_image_array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_kernel(kernel_size, blur=1/20, halo=.001):\n    \"\"\"\n    Create an (n*2+1)x(n*2+1) numpy array.\n    Output can be used as the kernel for convolution.\n    \"\"\"\n    \n    # generate x and y grids\n    x, y = np.mgrid[0:kernel_size*2+1, 0:kernel_size*2+1]\n    \n    center = kernel_size + 1  # center pixel\n    r = np.sqrt((x - center)**2 + (y - center)**2)  # distance from center\n    \n    # now compute the kernel. This function is a bit arbitrary. \n    # adjust this to get the effect you want.\n    kernel = np.exp(-r/kernel_size/blur) + (1 - r/r[center,0]).clip(0)*halo\n    return kernel\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_image(array, hue=.62):\n    \"\"\"converts an array of floats to an array of RGB values using a colormap\"\"\"\n    \n    # apply saturation function\n    image_data = np.log(array + 1)\n    \n    # create colormap, change these values to adjust to look of your plot\n    saturation_values = [[0, 0], [1, .68], [.78, .87], [0, 1]]\n    colors = [hsv_to_rgb([hue, x, y]) for x, y in saturation_values]\n    cmap = LinearSegmentedColormap.from_list(\"my_colormap\", colors)\n    \n    # apply colormap\n    out = cmap(image_data/image_data.max())\n    \n    # convert to 8-bit unsigned integer\n    out = (out*255).astype(np.uint8)\n    return out","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Convert Latitude and Longitude to Pixel Coordinates: Since folium (and leaflet.js) uses Mercator projection we can convert easily from latitude/longitude coordinates to pixel coordinates using a multiplier (i.e., y_pixel = A*latitude, x_pixel= B* longitude). We will choose A and B so that all our paths fit in the image and have the right aspect ratio."},{"metadata":{"trusted":true},"cell_type":"code","source":"min_lat = result[\"start_station_latitude\"].min()\nmax_lat = result[\"start_station_latitude\"].max()\nmax_lon = result[\"start_station_longitude\"].max()\nmin_lon = result[\"start_station_longitude\"].min()\n\ndef latlon_to_pixel(lat, lon, image_shape):\n    # longitude to pixel conversion (fit data to image)\n    delta_x = image_shape[1]/(max_lon-min_lon)\n    \n    # latitude to pixel conversion (maintain aspect ratio)\n    delta_y = delta_x/np.cos(lat/360*np.pi*2)\n    pixel_y = (max_lat-lat)*delta_y\n    pixel_x = (lon-min_lon)*delta_x\n    return (pixel_y,pixel_x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"and we’ll create a quick convenience function that applies this conversion to rows in our dataframe:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def row_to_pixel(row,image_shape):\n    \"\"\"\n    convert a row (1 trip) to pixel coordinates\n    of start and end point\n    \"\"\"\n    start_y, start_x = latlon_to_pixel(row[\"start_station_latitude\"], \n                                       row[\"start_station_longitude\"], image_shape)\n    end_y, end_x = latlon_to_pixel(row[\"end_station_latitude\"], \n                                   row[\"end_station_longitude\"], image_shape)\n    xy = (start_x, start_y, end_x, end_y)\n    return xy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#test\n''''paths = result\npaths = paths.iloc[:3000,:]\n# generate empty pixel array, choose your resolution\nimage_data = np.zeros((900,400))\n# generate pixel coordinates of starting points and end points\nxys = [row_to_pixel(row, image_data.shape) for i, row in paths.iterrows()]\n# draw the lines\nimage_data = add_lines(image_data, xys, weights=None, width = 1)\nImage.fromarray(to_image(image_data*10)[:,:,:3],mode=\"RGB\")'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_alpha(image_data):\n    \"\"\"\n    Uses the Value in HSV as an alpha channel. \n    This creates an image that blends nicely with a black background.\n    \"\"\"\n    \n    # get hsv image\n    hsv = rgb_to_hsv(image_data[:,:,:3].astype(float)/255)\n    \n    # create new image and set alpha channel\n    new_image_data = np.zeros(image_data.shape)\n    new_image_data[:,:,3] = hsv[:,:,2]\n    \n    # set value of hsv image to either 0 or 1.\n    hsv[:,:,2] = np.where(hsv[:,:,2]>0, 1, 0)\n    \n    # combine alpha and new rgb\n    new_image_data[:,:,:3] = hsv_to_rgb(hsv)\n    return new_image_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create the map\nimport folium\nfrom folium.plugins import MarkerCluster\n# create the map\nfolium_map = folium.Map(location=[59.9139, 10.7522],\n                        zoom_start=13,\n                        tiles=\"CartoDB dark_matter\",\n                        width='50%')\n\n# create the overlay\nmap_overlay = add_alpha(to_image(image_data*10))\n\n# compute extent of image in lat/lon\naspect_ratio = map_overlay.shape[1]/map_overlay.shape[0]\ndelta_lat = (max_lon-min_lon)/aspect_ratio*np.cos(min_lat/360*2*np.pi)\n\n# add the image to the map\nimg = folium.raster_layers.ImageOverlay(map_overlay,\n                           bounds = [(max_lat-delta_lat,min_lon),(max_lat,max_lon)],\n                           opacity = 1,\n                           name = \"Paths\")\n\nimg.add_to(folium_map)\nfolium.LayerControl().add_to(folium_map)\n\n# show the map\nfolium_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}